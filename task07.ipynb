{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# 决策树分类\n## 熵\n\u003e 熵最早来原于物理学. 德国物理学家鲁道夫·克劳修斯首次提出熵的概念，用来表示任何一种能量在空间中分布的均匀程度，能量分布得越均匀，熵就越大\n\n\u003e从微观看，熵就表现了这个系统所处状态的不确定性程度。香农，描述一个信息系统的时候就借用了熵的概念，这里熵表示的是这个信息系统的平均信息量(平均不确定程度)\n### 数学定义\n\n一个随机变量取值是离散的，取第i种情况的概率是$P_i$,比如扔硬币，正面朝上的概率是p，方面朝上概率是1-p\n\n定义这个分布的熵是：$H(p)\u003d-\\displaystyle\\sum_ip_i\\ln p_i$\n\n回到硬币的栗子\n\n$H(p)\u003d-p\\ln p-(1-p)\\ln (1-p)$\n\n$\\frac{dH(p)}{dp}\u003d\\ln \\frac{1-p}{p}\u003d0\\Rightarrow p\u003d\\frac{1}{2}$\n\n## 联合概率(Joint distribution)\n### 定义\n\n对于$(X,Y)二维随机变量，全部可能可以取得的值是有限对或则是无限对,则称$(X,Y)$是离散型随机变量.\n\n设二维离散型随机变量$(X,Y)$所有可能取到的值为$(x_i,y_j),i,j\u003d1,2...,$记$P(X\u003dx_i,Y\u003dy_i)\u003dp_{i,j},i,j\u003d1,2...,$则有概率的定义有\n\n$P_{i,j} \\geq 0; \\displaystyle \\sum_{i\u003d1}^{\\infty}\\sum_{j\u003d1}^{\\infty}p_{i,j}\u003d1$\n\n我们称$(x_i,y_j),i,j\u003d1,2...,$记$P(X\u003dx_i,Y\u003dy_i)\u003dp_{i,j},i,j\u003d1,2...,$是二维离散随机变量$(X,Y)$的分布律，或称随机变量X和Y的联合分布律\n\n计算方法：\n\n$P\\{X\u003di,Y\u003dj\\}\u003dP\\{Y\u003dj|X\u003di\\}P\\{X\u003di\\},i\u003d1,2,3...,j \\leq i$\n\n## 边缘概率(marginal distribution)\n### 定义\n\n- 提取出任意一个单一随机变量的分布，也就是所谓的边缘分布(marginal distribution)。\n\n对于离散型随机变量，可得X的边缘分布函数：\n\n$F_x(x)\u003dF(x,\\infty)\u003d\\displaystyle \\sum_{x_{x_i} \\leq x}\\displaystyle \\sum_{j\u003d x}^{\\infty} p_{i,j}$\n\n由此，我们得出X的分布律为：\n\n$P\\{X\u003dx_i\\}\u003d\\displaystyle \\sum_{j\u003d1}^{\\infty} p_{i,j},i\u003d1,2,...$\n\n记：$p_i\u003d\\displaystyle \\sum_{j\u003d1}^{\\infty}p_{ij}\u003dP\\{X\u003dx_i\\},i\u003d1,2,...$\n\n则称$p_i$为$(X,Y)$关于X的边缘分布律\n\n## 条件概率(propotal distribution)\n\n### 定义\n\n设A，B是两个事件，且 $P\\left( A \\right)\u003e0$, 称\n\n$P(B|A)\u003d\\frac{P(AB)}{P(A)}$\n\n为在事件A发生的条件下事件B发生的条件概率。\n\n## 推导条件熵定义公式\n![avatar](https://raw.githubusercontent.com/xmj-datawhale/lihongyi-ML/master/img/task6_joint_entropy1.png)\n## 联合熵\n### 定义\n\n代表X,Y同时发生的不确定性；公式为：$H(X,Y)\u003d-\\displaystyle \\sum_{x \\in X,y \\in Y}^{x,y}p(x,y)\\ln p(x,y)$这里的X,Y是随机变量的取值集合，从上图理解就是两个大圆的面积\n\n## 条件熵\n### 定义\n\n代表在已知一个变量发生的条件下，另一个变量发生所新增的不确定性；公式为：\n\n$H(X|Y)\u003dH(X,Y)-H(X)\u003d-\\displaystyle \\sum_{x \\in X,y \\in Y}^{x,y}p(x,y)\\ln p(x|y)$这里的X,Y是随机变量的取值集合，\n从上图中理解就是两个大圆去掉其中一个大圆所剩下的面积。\n\n最后定义互信息，其中的一个定义就是在已知X发生的条件下，Y不确定性减少的程度，这个定义在ID3算法中也叫信息增益，计算公式可以理解为：\n\n$I(X,Y)\u003dH(Y)-H(Y|X)\u003dH(Y)+H(X)-H(X,Y)$\n\n$\u003d\\displaystyle \\sum_{x \\in X,y \\in Y} p(x,y)\\ln \\frac{p(x,y)}{p(x)p(y)}$这里的X,Y是随机变量的取值集合，从上图理解就是两个大圆相交的面积，所以互信息是对偶的。\n\n## 相对熵 互信息\n$I(X,Y)\u003dD(p(x,y)||p(x)p(x))$\n\nKL散度$D(p(x,y)||p(x)p(x))$也叫做相对熵和交叉熵，交叉熵是互信息的第二定义\n\n交叉熵：代表两个概率分布（函数的相似度）\n\n计算公式:$P(p(x)||q(x))\u003d\\displaystyle \\sum_{x \\in X}p(x)\\ln \\frac{p(x)}{q(x)}\u003dE_{p(x)}\\ln \\frac{p(x)}{q(x)}$\n\u003e最后要解释的是最大熵的思想，最大熵原理指出，需要对一个随机事件的概率分布进行预测是，我们的预测应当满足全部已知的条件，未知的部分概率应该是均匀的，这样预测的风险最小，因为这时的信息熵最大，所以称这种模型为最大熵模型。举一个例子，如果没有任何已知条件下问你投一个骰子，出现5点的概率多大，这时假定所有的点数出现的概率是相等的一定是一种最保险的方法，这就是最大熵模型。\n\n最大熵的目标函数/模型函数：$P_{w}(y|x)\u003d\\frac{1}{Z_w(x)}e^{\\displaystyle \\sum_{i\u003d1}^nw_i f_i(x,y)}$,其中\n\n$Z_w(x)\u003d\\displaystyle \\sum_{y} e^{\\displaystyle \\sum_{i\u003d1}^nw_i f_i(x,y)}$\n\n\n## 互信息\n## 交叉熵 loss function\n\n## 最大熵公式推导\n\n参考：https://www.cnblogs.com/arachis/p/entropy.html\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nfrom collections import Counter\n\ndef calc_ShannonEnt(watermelon_3a):\n    watermelon_3a_labels \u003d watermelon_3a[watermelon_3a.columns.values[-1]]\n    labels_number \u003d Counter(watermelon_3a_labels)\n    watermelon_3a_shannonEnt \u003d 0.0\n    watermelon_3a_len \u003d len(watermelon_3a)\n    for label in labels_number:\n        temp \u003d labelCounts[label] / watermelon_3a_len\n        watermelon_3a_shannonEnt -\u003d temp * np.log2(temp)\n    return watermelon_3a_shannonEnt\n\nwatermelon_3a \u003d pd.read_csv(\"watermelon_3a.csv\")\nvalue \u003d calc_ShannonEnt(watermelon_3a)\nprint(\"该数据集的ShannonEnt为:\", value)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 决策树\n## CART树\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}