{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "\n@TOC【李宏毅机器学习任务二】\n\nhttps://shimo.im/docs/LrtvE7bsyewCWB14/read\n\n[datawhale学习笔记](https://datawhalechina.github.io/Leeml-Book/#/)\n\n观看观看李宏毅课程内容：P4、P5、P6、P7\n视频连接：\nhttps://www.bilibili.com/video/av35932863?from\u003dsearch\u0026seid\u003d8120828691691969718\n学习打卡内容：\n\n# 理解偏差和方差\n\n- 偏差：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，如下图第二行所示。\n- 方差：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，如下图右列所示。\n![avatar](https://raw.githubusercontent.com/xumajie/datawhale/master/lihongyi-ML/img/task02_bias_variace_01.jpg)\n- 噪音：这就简单了，就不是你想要的真正数据，你可以想象为来破坏你实验的元凶和造成你可能过拟合的原因之一，至于为什么是过拟合的原因，因为模型过度追求Low Bias会导致训练过度，对测试集判断表现优秀，导致噪声点也被拟合进去了\n\n## 学习误差为什么是偏差和方差而产生的，并且推导数学公式\n- 泛化误差（error）\n我们知道，算法在不同训练集上学得的结果很可能不同，即便这些训练集是来自于同一个分布。\n\n以回归任务为例，对测试样本$x$，令$y_D$为$x$在数据集上的标记，$y$为$x$的真实标记，由于噪声的存在，有可能$y_D$≠$y$，$f(x;D)$为在训练集D上学得函数$f$对$x$的预测输出。因此，算法的期望预测可以表示为 \n\n$\\bar{f}(x)\u003d\\mathbb E_D[f(x;D)]$\n\n不同训练集学得的函数ff的预测输出的方差（variance）为 \n\n$var(x)\u003d\\mathbb E_D[(f(x;D) - \\bar{f}(x))^2]$\n\n期望输出与真实标记之间的差距称为偏差（bias），即 \n\n$bias^2(x)\u003d(\\bar{f}(x)+{y})^2$\n\n噪声为 \n$\\varepsilon^2\u003d\\mathbb E_{D}[(y_{D} − y)^2]$\n\n为方便讨论，假定噪声期望为零，即\n\n$\\mathbb E_D[y_D−y]\u003d0$\n\n算法的期望泛化误差为 \n\n$E(f;D)\u003d\\mathbb E_D[(f(x;D)−y_D)^2]$\n\n$\u003d\\mathbb E_D[(f(x;D)−\\bar{f}(x)+\\bar{f}(x)−y_D)]^2$\n\n$\u003d\\mathbb E_D[(f(x;D)−\\bar{f}(x))^2]+\\mathbb E_D[(\\bar{f}(x)−y_D)^2]+\\mathbb E_D[2(f(x;D)−\\bar{f}(x))(\\bar{f}(x)−y_D)]$\n\n因为$(f(x;D)−\\bar{f}(x))$和$(\\bar{f}(x)−y_D)$相互独立，$\\mathbb E_D[2(f(x;D)−\\bar{f}(x))(\\bar{f}(x)−y_D)]\u003d2\\mathbb E_D[(f(x;D)−\\bar{f}(x))]\\mathbb E_D[(\\bar{f}(x)−y_D)]$\n根据期望预测公式：$\\bar{f}(x)\u003d\\mathbb E_D[f(x;D)]$有$\\mathbb E_D[(f(x;D)−\\bar{f}(x))]\u003d0$\n\n所以：$\u003d\\mathbb E_D[(f(x;D)−\\bar{f}(x))^2]+\\mathbb E_D[(\\bar{f}(x)−y_D)^2]$\n\n$\u003d\\mathbb E_D[(f(x;D)−\\bar{f}(x))^2]+\\mathbb E_D[(\\bar{f}(x)-y+y−y_D)^2]$\n\n$\u003d\\mathbb E_D[(f(x;D)−\\bar{f}(x))^2]+\\mathbb E_D[(\\bar{f}(x)+y)^2]+\\mathbb E_D[(y−y_D)^2]-\\mathbb E_D[2(\\bar{f}(x)+y)(y−y_D)]$\n\n同上：$\\mathbb E_D[2(\\bar{f}(x)+y)(y−y_D)]\u003d0$\n\n则：$\u003d\\mathbb E_D[(f(x;D)-\\bar{f}(x))^2]+\\mathbb E_D[(\\bar{f}(x)+y)^2]+\\mathbb E_D[(y−y_D)^2]$\n\n于是：\n$E(f;D)\u003dbias^2(x)+var(x)+\\varepsilon^2$\n\n也就是说，泛化误差可分解为偏差、方差与噪声之和。噪声无法人为控制，所以通常我们认为 \n\n$E(f;D)\u003dbias^2(x)+var(x)$\n\n现在知道了泛化误差来自哪，就需要进行针对性控制。\n\n## 过拟合，欠拟合，分别对应bias和variance什么情况\n\n- 欠拟合:还是以回归任务为例，看一个极端例子，$y\u003dc$，不论模型的训练数据如何变化，学得的函数都不会变，因此$f(x;D)$的输出都相同，即模型的稳定性非常好，但是对训练集的拟合也不是很好，显然对于测试样本的预测也不会很准确，这种对训练集刻画不足的情况，称为欠拟合（underfitting）。\n- 过拟合:复杂的模型将训练样本的特性当作全体样本的通性，将噪声引入了模型中，这种现象称之为过拟合（overfitting）\n\n所以我们需要在模型复杂度之间权衡，使偏差和方差得以均衡（trade-off），这样模型的整体误差才会最小。 \n\n![](https://raw.githubusercontent.com/xumajie/datawhale/master/lihongyi-ML/img/task02_unfiting_overfiting.png)\n\n### 欠拟合和过拟合应对策略\n### 欠拟合（刻画不够）\n\n- 寻找更好的特征，提升对数据的刻画能力\n- 增加特征数量\n- 重新选择更加复杂的模型\n\n### 过拟合（刻画太细，泛化太差）\n\n- 增加训练样本数量，样本多了，噪声比中就减少了\n- 减少特征维数，高维空间密度小\n- 加入正则化项，使得模型更加平滑\n\n# 学习鞍点，复习上次任务学习的全局最优和局部最优\n- 鞍点：一个不是局部极值点的驻点称为鞍点。\n- 驻点：函数在一点处的一阶导数为零\n- Hessian 矩阵:在数学中，Hessian 矩阵是标量值函数或标量场函数的二阶偏导数的方块矩阵。它描述了许多变量函数的局部曲率，可以用于判定多元函数的极值。假设有一实数函数 f: Rn→ R ，是关于输入 x (x ∈ Rn) 及输出 f(x) ∈ R 之间的关系式。如果其所有的二阶偏导数都存在，并且在该函数的领域上连续，那么 Hessian 矩阵 H 是一个 n×n 的矩阵，通常如下\n\n定义：\n\n![](https://raw.githubusercontent.com/xumajie/datawhale/master/lihongyi-ML/img/task02_hessian_matrix.jpg)\n\n#### 如何证明一个点为鞍点\n\nHessian 矩阵是一个凸函数，并且是正半定的。通过这一属性，我们可以测试临界点 x 是局部最大值，或者是局部最小值还是鞍点。如下所示：\n\n如果 H 在 x 处为正定矩阵时，则函数 f 在 x 处有一个局部极小值；\n如果 H 在 x 处为负定矩阵时，则函数 f 在 x 处有一个局部极大值；\n如果 H 在 x 处为不定矩阵时（即同时有正特征值和负特征值），则函数 f 在 x 处为鞍点。\n\n所以，一个简单标准的方法验证一个静止点是否为一个实数函数的鞍点，就是计算该函数的在该点上的 Hessian 矩阵。如果该 Hessian 矩阵为不定的，则该点为该函数的鞍点。\n\n#### 局部极小值和鞍点\n局部极小值和鞍点的相同点是，在该点处的梯度（导数）都为零。从上面可以看出，局部极小值和鞍点的区别就在于，在该点处的 Hessian 矩阵的特性。如果 Hessian 矩阵在该点处是正定的，则为局部极小值；如果为不定的，则为鞍点。\n\n鞍点通常是神经网络训练的困难之处。如下图所示，是一个包含两个参数的神经网络，是一个低维度的图，可以发现其存在很多的局部极小值，训练神经网络的时候，通常会陷入这些极小值中。事实上，建立的神经网络包含大量的参数，造成局部最优的困惑不是这些极小值点，而是零梯度点，通常为鞍点。\n\n## 解决办法有哪些\n- 算法优化\n- - 动向梯度下降\n- - RMSprop\n- - Adam 算法\n\n# 梯度下降\n## 学习Mini-Batch与SGD\n## 学习Batch与Mini-Batch，SGD梯度下降的区别\n\n梯度下降【Batch】：梯度下降就是我上面的推导，在梯度下降中，对于 $\\theta$  的更新，需要计算所有的样本然后求平均.其计算得到的是一个标准梯度。因而理论上来说一次更新的幅度是比较大的。\n\n随机梯度下降【SGD】：可以看到多了随机两个字，随机也就是说我每次用样本中的一个例子来近似我所有的样本，用这一个例子来计算梯度并用这个梯度来更新$\\theta$ 。因为每次只用了一个样本因而容易陷入到局部最优解中\n\n批量随机梯度下降[Mini-Batch]：他用了一些小样本来近似全部的，其本质就是竟然1个样本的近似不一定准，那就用更大的30个或50个样本来近似。将样本分成m个mini-batch，每个mini-batch包含n个样本；在每个mini-batch里计算每个样本的梯度，然后在这个mini-batch里求和取平均作为最终的梯度来更新参数；然后再用下一个mini-batch来计算梯度，如此循环下去直到m个mini-batch操作完就称为一个epoch结束。\n\n## 如何根据样本大小选择哪个梯度下降(批量梯度下降，Mini-Batch）\n## 写出SGD和Mini-Batch的代码\n\nBatch\nBatch gradient descent 就是一次迭代训练所有样本，就这样不停的迭代。整个算法的框架可以表\n```\nX \u003d data_input\nY \u003d labels\nparameters \u003d initialize_parameters(layers_dims)\nfor i in range(0, num_iterations): #num_iterations--迭代次数\n    # Forward propagation\n    a, caches \u003d forward_propagation(X, parameters)\n    # Compute cost.\n    cost \u003d compute_cost(a, Y)\n    # Backward propagation.\n    grads \u003d backward_propagation(a, caches, parameters)\n    # Update parameters.\n    parameters \u003d update_parameters(parameters, grads)\n```\n\u003eBatch gradient descent的优点是理想状态下经过足够多的迭代后可以达到全局最优。但是缺点也很明显，就是如果你的数据集非常的大（现在很常见），根本没法全部塞到内存（显存）里，所以BGD对于小样本还行，大数据集就没法娱乐了。而且因为每次迭代都要计算全部的样本，所以对于大数据量会非常的慢。\n\nSGD\n\n```\nX \u003d data_input\nY \u003d labels\npermutation \u003d list(np.random.permutation(m))\nshuffled_X \u003d X[:, permutation]\nshuffled_Y \u003d Y[:, permutation].reshape((1, m))\nfor i in range(0, num_iterations):\n    for j in range(0, m):  # 每次训练一个样本\n        # Forward propagation\n        AL,caches \u003d forward_propagation(shuffled_X[:, j].reshape(-1,1), parameters)\n        # Compute cost\n        cost \u003d compute_cost(AL, shuffled_Y[:, j].reshape(1,1))\n        # Backward propagation\n        grads \u003d backward_propagation(AL, shuffled_Y[:,j].reshape(1,1), caches)\n        # Update parameters.\n        parameters \u003d update_parameters(parameters, grads, learning_rate)\n```\n\n\u003e如果我们的数据集很大，比如几亿条数据，num\\_iterations 基本上 设置1，2，（10以内的就足够了）就可以。但是SGD也有缺点，因为每次只用一个样本来更新参数，会导致不稳定性大些(可以看下图（图片来自ng deep learning 课），每次更新的方向，不想batch gradient descent那样每次都朝着最优点的方向逼近，会在最优点附近震荡）。因为每次训练的都是随机的一个样本，会导致导致梯度的方向不会像BGD那样朝着最优点。 \n注意：代码中的随机把数据打乱很重要，因为这个随机性相当于引入了“噪音”，正是因为这个噪音，使得SGD可能会避免陷入局部最优解中。\n下面来对比下SGD和BGD的代价函数随着迭代次数的变化图：\n\n![](https://raw.githubusercontent.com/xumajie/datawhale/master/lihongyi-ML/img/task02_sgd.png)\n\n下面来对比下SGD和BGD的代价函数随着迭代次数的变化图：\n![](https://raw.githubusercontent.com/xumajie/datawhale/master/lihongyi-ML/img/task02_sgd_mbgd-iter.png)\n\n1.首先要把训练集分成多个batch\n```\n# GRADED FUNCTION: random_mini_batches\ndef random_mini_batches(X, Y, mini_batch_size \u003d 64, seed \u003d 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    Arguments:\n    X -- input data, of shape (input size, number of examples)\n    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n    mini_batch_size -- size of the mini-batches, integer\n\n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n    m \u003d X.shape[1]                  # number of training examples\n    mini_batches \u003d []\n\n    # Step 1: Shuffle (X, Y)\n    permutation \u003d list(np.random.permutation(m))\n    shuffled_X \u003d X[:, permutation]\n    shuffled_Y \u003d Y[:, permutation].reshape((1,m))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches \u003d m//mini_batch_size # number of mini batches\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X \u003d shuffled_X[:, k * mini_batch_size: (k + 1) * mini_batch_size]\n        mini_batch_Y \u003d shuffled_Y[:, k * mini_batch_size: (k + 1) * mini_batch_size]\n        mini_batch \u003d (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n\n    # Handling the end case (last mini-batch \u003c mini_batch_size)\n    if m % mini_batch_size !\u003d 0:\n        mini_batch_X \u003d shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n        mini_batch_Y \u003d shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n        mini_batch \u003d (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n\n    return mini_batches\n```\n\n2.下面是在model中使用mini-batch gradient descent 进行更新参数\n```\nseed \u003d 0\nfor i in range(0, num_iterations):\n    # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n    seed \u003d seed + 1\n    minibatches \u003d random_mini_batches(X, Y, mini_batch_size, seed)\n    for minibatch in minibatches:\n        # Select a minibatch\n        (minibatch_X, minibatch_Y) \u003d minibatch\n        # Forward propagation\n        AL, caches \u003d forward_propagation(minibatch_X, parameters)\n        # Compute cost\n        cost \u003d compute_cost(AL, minibatch_Y)\n        # Backward propagation\n        grads \u003d backward_propagation(AL, minibatch_Y, caches)\n        parameters \u003d update_parameters(parameters, grads, learning_rate)\n```\n下面来看mini-batch gradient descent 和 stochastic gradient descent 在下降时的对比图：\n![](https://raw.githubusercontent.com/xumajie/datawhale/master/lihongyi-ML/img/task02_sgd_mini-bgd-diff.png)\n\n下面是mini-batch gradient descent的代价函数随着迭代次数的变化图：\n![](https://raw.githubusercontent.com/xumajie/datawhale/master/lihongyi-ML/img/task02_mbgd-iterater.png)\n\n\u003e从图中能够看出，mini-batch gradient descent 相对SGD在下降的时候，相对平滑些（相对稳定），不像SGD那样震荡的比较厉害。mini-batch gradient descent的一个缺点是增加了一个超参数 batch\\_size ，要去调这个超参数。 \n以上就是关于batch gradient descent、mini-batch gradient descent 和 stochastic gradient descent的内容。 \n\n# 学习交叉验证\n\n参考：https://www.cnblogs.com/pinard/p/5992719.html\n\n三种方式\n- 简单交叉验证\n- S折交叉验证【S-Folder Cross Valication】\n- 留一交叉验证【Leave-one-out Cross Valication】\n\n# 学习归一化 \n\n１）把数据变成(０，１)或者（1,1）之间的小数。主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速。\n\n２）把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。\n\n归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。\n\n\n# 学习回归模型评价指标\n\n1、均方误差【Mean Squar Error,MSE】\n\n$MSE\u003d\\frac{1}{m}\\sum_{i\u003d1}^{m}(f_i-y_i)^2$\n\n2、均方根误差（变准误差）【Root Mean Squar Error，rmse】\n\n$rmse\u003d\\sqrt{\\frac{1}{m}\\sum_{i\u003d1}^{m}(f_i-y_i)^2}$\n\n3、平均绝对误差【Mean Absolute Error；MAE】\n\n$MAE\u003d\\frac{1}{m}\\sum_{i\u003d1}^{m}|f_i-y_i|$\n\n4、R平方【R_Squared】\n\n\n$R^2\u003d1-\\frac{SS_{residual}}{SS_{total}}$\n\n$\u003d1-\\frac{\\sum_{i\u003d1}^m (\\bar f_i-y_i)^2}{\\sum_{i\u003d1}^m (\\bar y_i-y_i)^2}$\n\n上面分子就是我们训练出的模型预测的误差和。\n\n下面分母就是瞎猜的误差和。（通常取观测值的平均值）\n\n\n参考：\n\nhttps://blog.csdn.net/hohaizx/article/details/80640686\n\nhttps://www.jianshu.com/p/81ecc47bb9b0\n\nhttps://juejin.im/entry/5b74d443f265da2839585164\n\n"
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}